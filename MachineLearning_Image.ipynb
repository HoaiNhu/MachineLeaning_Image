{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "KulhSOkAhhmR"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HoaiNhu/MachineLeaning_Image/blob/main/MachineLearning_Image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dAP5AuP_ElR0",
        "outputId": "1746a859-f325-459d-d610-471e4e4abff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tải ảnh**"
      ],
      "metadata": {
        "id": "OPwYjCDYNM0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bing-image-downloader\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27stycYfNO0K",
        "outputId": "acb1dfaf-ce6a-438d-efb8-dbab26b12805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bing-image-downloader in /usr/local/lib/python3.10/dist-packages (1.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bing_image_downloader import downloader\n",
        "\n",
        "# Thêm nhiều nhãn hơn vào danh sách\n",
        "labels = [\"apple\", \"cat\", \"flag\", \"dog\", \"car\", \"flower\", \"banana\", \"sun\", \"tree\", \"book\", \"laptop\", \"phone\", \"water\",\n",
        "    \"mountain\", \"bird\", \"ball\", \"train\", \"house\", \"elephant\", \"tiger\", \"lion\", \"rabbit\", \"horse\",\n",
        "    \"grass\", \"cactus\", \"palm tree\", \"mango\",\n",
        "    \"chair\", \"bottle\", \"cup\", \"table\", \"bag\",\n",
        "    \"beach\", \"forest\", \"desert\", \"ocean\", \"city\",\n",
        "    \"bicycle\", \"clock\", \"pen\", \"shoes\",  \"cow\", \"goat\", \"sheep\", \"duck\", \"fish\", \"penguin\", \"panda\",\n",
        "    \"rose\", \"pine tree\", \"orchid\", \"bamboo\", \"sunflower\",\n",
        "    \"key\", \"hat\", \"basketball\", \"pencil\", \"guitar\",\n",
        "    \"river\", \"waterfall\", \"sky\", \"volcano\",\n",
        "    \"airplane\", \"ship\", \"pizza\", \"cake\", \"bread\", \"candle\"]\n",
        "\n",
        "\n",
        "# Tải xuống hình ảnh cho mỗi nhãn\n",
        "for label in labels:\n",
        "    downloader.download(label, limit=100, output_dir='dataset_image', adult_filter_off=True, force_replace=False, timeout=60)\n",
        "\n"
      ],
      "metadata": {
        "id": "zp-2um7aQugH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import ảnh từ drive"
      ],
      "metadata": {
        "id": "BH2Uzu7VfZ0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tJQLSpZJ6lus",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b0f9ba8-6f77-40a9-ed1d-df805cd5e779"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tổng ảnh trong dataset**"
      ],
      "metadata": {
        "id": "N0gpoEeT_GuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def count_images(dataset_path):\n",
        "    total_images = 0\n",
        "    for label_dir in os.listdir(dataset_path):\n",
        "        label_path = os.path.join(dataset_path, label_dir)\n",
        "        if os.path.isdir(label_path):\n",
        "            num_images = len([file for file in os.listdir(label_path) if file.endswith(('png', 'jpg', 'jpeg'))])\n",
        "            print(f\"{label_dir}: {num_images} images\")\n",
        "            total_images += num_images\n",
        "    print(f\"Total images: {total_images}\")\n",
        "    return total_images\n",
        "\n",
        "# Thay 'dataset' bằng đường dẫn đến thư mục dữ liệu của bạn\n",
        "count_images('drive/MyDrive/dataset_image')\n"
      ],
      "metadata": {
        "id": "m-Oqckmg_NI4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "b382f05f-e7f1-447a-c1a5-54ec0f0dd13d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apple: 100 images\n",
            "cat: 98 images\n",
            "flag: 97 images\n",
            "dog: 100 images\n",
            "car: 97 images\n",
            "flower: 99 images\n",
            "banana: 99 images\n",
            "sun: 98 images\n",
            "tree: 97 images\n",
            "book: 99 images\n",
            "laptop: 97 images\n",
            "phone: 100 images\n",
            "water: 97 images\n",
            "mountain: 100 images\n",
            "bird: 100 images\n",
            "ball: 95 images\n",
            "train: 98 images\n",
            "house: 95 images\n",
            "elephant: 95 images\n",
            "tiger: 100 images\n",
            "lion: 98 images\n",
            "rabbit: 98 images\n",
            "horse: 98 images\n",
            "grass: 94 images\n",
            "cactus: 95 images\n",
            "palm tree: 98 images\n",
            "mango: 96 images\n",
            "chair: 100 images\n",
            "bottle: 98 images\n",
            "cup: 100 images\n",
            "table: 98 images\n",
            "bag: 98 images\n",
            "beach: 100 images\n",
            "forest: 99 images\n",
            "desert: 95 images\n",
            "ocean: 97 images\n",
            "city: 99 images\n",
            "bicycle: 97 images\n",
            "clock: 99 images\n",
            "pen: 100 images\n",
            "shoes: 99 images\n",
            "cow: 98 images\n",
            "goat: 97 images\n",
            "sheep: 97 images\n",
            "duck: 99 images\n",
            "fish: 98 images\n",
            "penguin: 99 images\n",
            "panda: 96 images\n",
            "rose: 94 images\n",
            "pine tree: 99 images\n",
            "orchid: 95 images\n",
            "bamboo: 99 images\n",
            "sunflower: 98 images\n",
            "key: 99 images\n",
            "hat: 98 images\n",
            "basketball: 97 images\n",
            "pencil: 96 images\n",
            "guitar: 99 images\n",
            "river: 97 images\n",
            "waterfall: 99 images\n",
            "sky: 99 images\n",
            "volcano: 98 images\n",
            "airplane: 96 images\n",
            "ship: 100 images\n",
            "pizza: 99 images\n",
            "cake: 99 images\n",
            "bread: 97 images\n",
            "candle: 97 images\n",
            "Total images: 6656\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6656"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Sao chép thư mục dataset vào Google Drive\n",
        "!cp -r dataset /content/drive/MyDrive/\n"
      ],
      "metadata": {
        "id": "OeNSP5phhmJl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7218178a-4f27-456f-f43a-89bbec6403a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Copy Dataset từ Drive**"
      ],
      "metadata": {
        "id": "Dx1poUFImhlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2p82fVC8m4av",
        "outputId": "4c7ad4a5-1f90-4850-e51b-17f10827b925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/drive/My Drive': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/My Drive/dataset_image/\" /content/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xG8Z__vTmm7g",
        "outputId": "de0bf867-c330-4f34-84fd-d82b10272ffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/drive/My Drive/dataset_image/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Xóa folder**"
      ],
      "metadata": {
        "id": "KulhSOkAhhmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Đường dẫn đến thư mục cần xóa\n",
        "folder_path = \"dataset/fruit\"  # Thay bằng đường dẫn thư mục của bạn\n",
        "\n",
        "if os.path.exists(folder_path):\n",
        "    shutil.rmtree(folder_path)\n",
        "    print(f\"Đã xóa thư mục: {folder_path}\")\n",
        "else:\n",
        "    print(f\"Thư mục không tồn tại: {folder_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEQWfPCvbNWU",
        "outputId": "454a2496-869e-4118-bf21-34c9d09e164f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đã xóa thư mục: dataset/fruit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Xây dựng chương trình**"
      ],
      "metadata": {
        "id": "Ia08j27CJ82H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lpiQwwaT5-Z",
        "outputId": "8e108b0b-0fb9-4d61-cf93-55973b883e85"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ne2iD0thjIR",
        "outputId": "60006211-e2a2-443a-abb7-f42f91314a45"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip show tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-_QEibIT_lw",
        "outputId": "b9195b36-f960-429e-fd15-c92dbcf099a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.18.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
            "Required-by: dopamine_rl, tf_keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade tensorflow\n"
      ],
      "metadata": {
        "id": "qH15Qm4MkJoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pip install keras --upgrade\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Fu4_uMLmUM6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Đường dẫn tới dataset\n",
        "DATASET_PATH = '/content/drive/MyDrive/dataset_image'\n",
        "\n",
        "# Kiểm tra và xử lý hình ảnh không hợp lệ\n",
        "def clean_dataset(path):\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            try:\n",
        "                with Image.open(file_path) as img:\n",
        "                    if img.mode != 'RGB':\n",
        "                        img = img.convert('RGB')\n",
        "                        img.save(file_path)\n",
        "            except Exception as e:\n",
        "                print(f\"Invalid image found: {file_path}, removing it.\")\n",
        "                os.remove(file_path)\n",
        "\n",
        "clean_dataset(DATASET_PATH)\n",
        "\n",
        "# Chuẩn bị dữ liệu\n",
        "image_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    validation_split=0.2,  # 20% cho tập validation\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Tải mô hình pretrained ResNet50\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Đóng băng các lớp trong base model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Thêm các lớp fully connected\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "\n",
        "# Xây dựng model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Huấn luyện model\n",
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator\n",
        ")\n",
        "\n",
        "# Lưu model\n",
        "model.save('image_classifier_resnet50.h5')\n",
        "\n",
        "# Đánh giá model\n",
        "loss, accuracy = model.evaluate(val_generator)\n",
        "print(f'Validation Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN8aGodhJ-W6",
        "outputId": "62e62392-d289-45e0-89ce-dc4d2e7b2db0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5415 images belonging to 68 classes.\n",
            "Found 1332 images belonging to 68 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1313s\u001b[0m 7s/step - accuracy: 0.0265 - loss: 4.2606 - val_accuracy: 0.0480 - val_loss: 4.1231\n",
            "Epoch 2/10\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 2s/step - accuracy: 0.0380 - loss: 4.1083 - val_accuracy: 0.0758 - val_loss: 4.0103\n",
            "Epoch 3/10\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 2s/step - accuracy: 0.0654 - loss: 3.9648 - val_accuracy: 0.0833 - val_loss: 3.9298\n",
            "Epoch 4/10\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 2s/step - accuracy: 0.0771 - loss: 3.8691 - val_accuracy: 0.0931 - val_loss: 3.8909\n",
            "Epoch 5/10\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 2s/step - accuracy: 0.0996 - loss: 3.7883 - val_accuracy: 0.1029 - val_loss: 3.7998\n",
            "Epoch 6/10\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 2s/step - accuracy: 0.1188 - loss: 3.7144 - val_accuracy: 0.1149 - val_loss: 3.7488\n",
            "Epoch 7/10\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 2s/step - accuracy: 0.1220 - loss: 3.6405 - val_accuracy: 0.1171 - val_loss: 3.7179\n",
            "Epoch 8/10\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 2s/step - accuracy: 0.1478 - loss: 3.5804 - val_accuracy: 0.1299 - val_loss: 3.6828\n",
            "Epoch 9/10\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 2s/step - accuracy: 0.1434 - loss: 3.5691 - val_accuracy: 0.1456 - val_loss: 3.6580\n",
            "Epoch 10/10\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 2s/step - accuracy: 0.1543 - loss: 3.5005 - val_accuracy: 0.1434 - val_loss: 3.6238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 1s/step - accuracy: 0.1238 - loss: 3.6320\n",
            "Validation Accuracy: 14.34%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tải lại model"
      ],
      "metadata": {
        "id": "BqwCRNOM4cUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Tải lại mô hình đã lưu\n",
        "model = load_model('image_classifier_resnet50.h5')\n"
      ],
      "metadata": {
        "id": "B7_VhPbi4d95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tiếp tục huấn luyện"
      ],
      "metadata": {
        "id": "SszSzPwP4e17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tiếp tục huấn luyện mô hình từ epoch 11\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=20,  # Tổng số epoch bạn muốn huấn luyện\n",
        "    initial_epoch=10,  # Bắt đầu từ epoch 11\n",
        "    validation_data=val_generator\n",
        ")\n"
      ],
      "metadata": {
        "id": "q8SP9mwM4gpe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}