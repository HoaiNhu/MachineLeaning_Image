{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "KulhSOkAhhmR"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HoaiNhu/MachineLeaning_Image/blob/main/MachineLearning_Image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dAP5AuP_ElR0",
        "outputId": "1746a859-f325-459d-d610-471e4e4abff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tải ảnh**"
      ],
      "metadata": {
        "id": "OPwYjCDYNM0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bing-image-downloader\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27stycYfNO0K",
        "outputId": "acb1dfaf-ce6a-438d-efb8-dbab26b12805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bing-image-downloader in /usr/local/lib/python3.10/dist-packages (1.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bing_image_downloader import downloader\n",
        "\n",
        "# Thêm nhiều nhãn hơn vào danh sách\n",
        "labels = [\"apple\", \"cat\", \"flag\", \"dog\", \"car\", \"flower\", \"banana\", \"sun\", \"tree\", \"book\", \"laptop\", \"phone\", \"water\",\n",
        "    \"mountain\", \"bird\", \"ball\", \"train\", \"house\", \"elephant\", \"tiger\", \"lion\", \"rabbit\", \"horse\",\n",
        "    \"grass\", \"cactus\", \"palm tree\", \"mango\",\n",
        "    \"chair\", \"bottle\", \"cup\", \"table\", \"bag\",\n",
        "    \"beach\", \"forest\", \"desert\", \"ocean\", \"city\",\n",
        "    \"bicycle\", \"clock\", \"pen\", \"shoes\",  \"cow\", \"goat\", \"sheep\", \"duck\", \"fish\", \"penguin\", \"panda\",\n",
        "    \"rose\", \"pine tree\", \"orchid\", \"bamboo\", \"sunflower\",\n",
        "    \"key\", \"hat\", \"basketball\", \"pencil\", \"guitar\",\n",
        "    \"river\", \"waterfall\", \"sky\", \"volcano\",\n",
        "    \"airplane\", \"ship\", \"pizza\", \"cake\", \"bread\", \"candle\"]\n",
        "\n",
        "\n",
        "# Tải xuống hình ảnh cho mỗi nhãn\n",
        "for label in labels:\n",
        "    downloader.download(label, limit=100, output_dir='dataset_image', adult_filter_off=True, force_replace=False, timeout=60)\n",
        "\n"
      ],
      "metadata": {
        "id": "zp-2um7aQugH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import ảnh từ drive"
      ],
      "metadata": {
        "id": "BH2Uzu7VfZ0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tJQLSpZJ6lus",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b511d9d-00c8-47d0-f884-6596d86abaa3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tổng ảnh trong dataset**"
      ],
      "metadata": {
        "id": "N0gpoEeT_GuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def count_images(dataset_path):\n",
        "    total_images = 0\n",
        "    for label_dir in os.listdir(dataset_path):\n",
        "        label_path = os.path.join(dataset_path, label_dir)\n",
        "        if os.path.isdir(label_path):\n",
        "            num_images = len([file for file in os.listdir(label_path) if file.endswith(('png', 'jpg', 'jpeg'))])\n",
        "            print(f\"{label_dir}: {num_images} images\")\n",
        "            total_images += num_images\n",
        "    print(f\"Total images: {total_images}\")\n",
        "    return total_images\n",
        "\n",
        "# Thay 'dataset' bằng đường dẫn đến thư mục dữ liệu của bạn\n",
        "count_images('drive/MyDrive/dataset_image')\n"
      ],
      "metadata": {
        "id": "m-Oqckmg_NI4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "b382f05f-e7f1-447a-c1a5-54ec0f0dd13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apple: 100 images\n",
            "cat: 98 images\n",
            "flag: 97 images\n",
            "dog: 100 images\n",
            "car: 97 images\n",
            "flower: 99 images\n",
            "banana: 99 images\n",
            "sun: 98 images\n",
            "tree: 97 images\n",
            "book: 99 images\n",
            "laptop: 97 images\n",
            "phone: 100 images\n",
            "water: 97 images\n",
            "mountain: 100 images\n",
            "bird: 100 images\n",
            "ball: 95 images\n",
            "train: 98 images\n",
            "house: 95 images\n",
            "elephant: 95 images\n",
            "tiger: 100 images\n",
            "lion: 98 images\n",
            "rabbit: 98 images\n",
            "horse: 98 images\n",
            "grass: 94 images\n",
            "cactus: 95 images\n",
            "palm tree: 98 images\n",
            "mango: 96 images\n",
            "chair: 100 images\n",
            "bottle: 98 images\n",
            "cup: 100 images\n",
            "table: 98 images\n",
            "bag: 98 images\n",
            "beach: 100 images\n",
            "forest: 99 images\n",
            "desert: 95 images\n",
            "ocean: 97 images\n",
            "city: 99 images\n",
            "bicycle: 97 images\n",
            "clock: 99 images\n",
            "pen: 100 images\n",
            "shoes: 99 images\n",
            "cow: 98 images\n",
            "goat: 97 images\n",
            "sheep: 97 images\n",
            "duck: 99 images\n",
            "fish: 98 images\n",
            "penguin: 99 images\n",
            "panda: 96 images\n",
            "rose: 94 images\n",
            "pine tree: 99 images\n",
            "orchid: 95 images\n",
            "bamboo: 99 images\n",
            "sunflower: 98 images\n",
            "key: 99 images\n",
            "hat: 98 images\n",
            "basketball: 97 images\n",
            "pencil: 96 images\n",
            "guitar: 99 images\n",
            "river: 97 images\n",
            "waterfall: 99 images\n",
            "sky: 99 images\n",
            "volcano: 98 images\n",
            "airplane: 96 images\n",
            "ship: 100 images\n",
            "pizza: 99 images\n",
            "cake: 99 images\n",
            "bread: 97 images\n",
            "candle: 97 images\n",
            "Total images: 6656\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6656"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Sao chép thư mục dataset vào Google Drive\n",
        "!cp -r dataset /content/drive/MyDrive/\n"
      ],
      "metadata": {
        "id": "OeNSP5phhmJl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7218178a-4f27-456f-f43a-89bbec6403a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Copy Dataset từ Drive**"
      ],
      "metadata": {
        "id": "Dx1poUFImhlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive\"\n"
      ],
      "metadata": {
        "id": "2p82fVC8m4av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/My Drive/dataset_image/\" /content/\n"
      ],
      "metadata": {
        "id": "xG8Z__vTmm7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Xóa folder**"
      ],
      "metadata": {
        "id": "KulhSOkAhhmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Đường dẫn đến thư mục cần xóa\n",
        "folder_path = \"dataset/fruit\"  # Thay bằng đường dẫn thư mục của bạn\n",
        "\n",
        "if os.path.exists(folder_path):\n",
        "    shutil.rmtree(folder_path)\n",
        "    print(f\"Đã xóa thư mục: {folder_path}\")\n",
        "else:\n",
        "    print(f\"Thư mục không tồn tại: {folder_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEQWfPCvbNWU",
        "outputId": "454a2496-869e-4118-bf21-34c9d09e164f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đã xóa thư mục: dataset/fruit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Xây dựng chương trình**"
      ],
      "metadata": {
        "id": "Ia08j27CJ82H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lpiQwwaT5-Z",
        "outputId": "8e108b0b-0fb9-4d61-cf93-55973b883e85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ne2iD0thjIR",
        "outputId": "60006211-e2a2-443a-abb7-f42f91314a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip show tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-_QEibIT_lw",
        "outputId": "b9195b36-f960-429e-fd15-c92dbcf099a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.18.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
            "Required-by: dopamine_rl, tf_keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade tensorflow\n"
      ],
      "metadata": {
        "id": "qH15Qm4MkJoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pip install keras --upgrade\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Fu4_uMLmUM6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Đường dẫn tới dataset\n",
        "DATASET_PATH = '/content/drive/MyDrive/dataset_image'\n",
        "\n",
        "# Kiểm tra và xử lý hình ảnh không hợp lệ\n",
        "def clean_dataset(path):\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            try:\n",
        "                with Image.open(file_path) as img:\n",
        "                    if img.mode != 'RGB':\n",
        "                        img = img.convert('RGB')\n",
        "                        img.save(file_path)\n",
        "            except Exception as e:\n",
        "                print(f\"Invalid image found: {file_path}, removing it.\")\n",
        "                os.remove(file_path)\n",
        "\n",
        "clean_dataset(DATASET_PATH)\n",
        "\n",
        "# Chuẩn bị dữ liệu\n",
        "image_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    validation_split=0.2,  # 20% cho tập validation\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Tải mô hình pretrained ResNet50\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Đóng băng các lớp trong base model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Thêm các lớp fully connected\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "\n",
        "# Xây dựng model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Huấn luyện model\n",
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator\n",
        ")\n",
        "\n",
        "# Lưu model\n",
        "model.save('/content/drive/MyDrive/image_classifier_resnet50.h5', include_optimizer=True)\n",
        "print(\"Model saved to Google Drive!\")\n",
        "\n",
        "\n",
        "# Đánh giá model\n",
        "loss, accuracy = model.evaluate(val_generator)\n",
        "print(f'Validation Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN8aGodhJ-W6",
        "outputId": "73f1846a-b672-4f1f-d241-32ece54876a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5415 images belonging to 68 classes.\n",
            "Found 1332 images belonging to 68 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1450s\u001b[0m 8s/step - accuracy: 0.0196 - loss: 4.2507 - val_accuracy: 0.0330 - val_loss: 4.1513\n",
            "Epoch 2/10\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1474s\u001b[0m 9s/step - accuracy: 0.0294 - loss: 4.1384 - val_accuracy: 0.0548 - val_loss: 4.0682\n",
            "Epoch 3/10\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1486s\u001b[0m 8s/step - accuracy: 0.0577 - loss: 4.0329 - val_accuracy: 0.0721 - val_loss: 3.9787\n",
            "Epoch 4/10\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1427s\u001b[0m 8s/step - accuracy: 0.0803 - loss: 3.9227 - val_accuracy: 0.0841 - val_loss: 3.8958\n",
            "Epoch 5/10\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1460s\u001b[0m 9s/step - accuracy: 0.1011 - loss: 3.8254 - val_accuracy: 0.1006 - val_loss: 3.8351\n",
            "Epoch 6/10\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1471s\u001b[0m 9s/step - accuracy: 0.0936 - loss: 3.7692 - val_accuracy: 0.1051 - val_loss: 3.7759\n",
            "Epoch 7/10\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1438s\u001b[0m 8s/step - accuracy: 0.1097 - loss: 3.7182 - val_accuracy: 0.1194 - val_loss: 3.7234\n",
            "Epoch 8/10\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1475s\u001b[0m 9s/step - accuracy: 0.1348 - loss: 3.6561 - val_accuracy: 0.1149 - val_loss: 3.7103\n",
            "Epoch 9/10\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1457s\u001b[0m 8s/step - accuracy: 0.1334 - loss: 3.6245 - val_accuracy: 0.1141 - val_loss: 3.6924\n",
            "Epoch 10/10\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1464s\u001b[0m 9s/step - accuracy: 0.1389 - loss: 3.5809 - val_accuracy: 0.1419 - val_loss: 3.6435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to Google Drive!\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 7s/step - accuracy: 0.1230 - loss: 3.5882\n",
            "Validation Accuracy: 14.19%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tải lại model"
      ],
      "metadata": {
        "id": "BqwCRNOM4cUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"Current working directory:\", os.getcwd())\n",
        "print(\"Files in directory:\", os.listdir())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j9fYFa4BweZ",
        "outputId": "7668344d-ec91-4cf1-8a4f-514cfcb3708b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content\n",
            "Files in directory: ['.config', 'drive', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Tải mô hình\n",
        "model = load_model('/content/drive/MyDrive/image_classifier_resnet50.h5')\n",
        "\n",
        "# Compile lại mô hình\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "B7_VhPbi4d95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0cd6bf8-875e-4352-ff98-42710cda361e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tiếp tục huấn luyện"
      ],
      "metadata": {
        "id": "SszSzPwP4e17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Đường dẫn tới dataset\n",
        "DATASET_PATH = '/content/drive/MyDrive/dataset_image'\n",
        "\n",
        "# Chuẩn bị dữ liệu\n",
        "image_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    validation_split=0.2,  # 20% cho tập validation\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nHcxG6LwIm2",
        "outputId": "3a598ec4-0786-4595-90fb-bbea563bdbc8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5415 images belonging to 68 classes.\n",
            "Found 1332 images belonging to 68 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/image_classifier_resnet50.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "880o9UARwMJL",
        "outputId": "7b15246d-5d47-4d7d-de1e-81563c3d49d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Tải lại mô hình\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/image_classifier_resnet50.h5')\n",
        "\n",
        "# Khởi tạo lại optimizer và compile lại mô hình\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Tiếp tục huấn luyện từ epoch 11\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=45,  # Tổng số epoch bạn muốn huấn luyện\n",
        "    initial_epoch=40,  # Bắt đầu từ epoch 11\n",
        "    validation_data=val_generator\n",
        ")\n"
      ],
      "metadata": {
        "id": "q8SP9mwM4gpe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1af03823-46ea-49b4-c9dd-cf9c8cf2e6bb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3298s\u001b[0m 19s/step - accuracy: 0.2706 - loss: 2.9745 - val_accuracy: 0.1922 - val_loss: 3.4115\n",
            "Epoch 42/45\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1552s\u001b[0m 9s/step - accuracy: 0.2911 - loss: 2.9322 - val_accuracy: 0.1682 - val_loss: 3.4594\n",
            "Epoch 43/45\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1565s\u001b[0m 9s/step - accuracy: 0.2759 - loss: 2.9079 - val_accuracy: 0.1809 - val_loss: 3.4384\n",
            "Epoch 44/45\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1534s\u001b[0m 9s/step - accuracy: 0.2861 - loss: 2.8984 - val_accuracy: 0.1989 - val_loss: 3.4199\n",
            "Epoch 45/45\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1578s\u001b[0m 9s/step - accuracy: 0.2838 - loss: 2.9139 - val_accuracy: 0.1802 - val_loss: 3.4047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lưu mô hình sau khi hoàn tất huấn luyện\n",
        "model.save('/content/drive/MyDrive/image_classifier_resnet50.h5', include_optimizer=True)\n",
        "# model.save('/content/drive/MyDrive/image_classifier_resnet50.h5')\n",
        "print(\"Model saved at drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJvcY9h91EBb",
        "outputId": "7649e472-9e49-4f68-e6a4-742c8d3cdcdd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved at drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Detection**"
      ],
      "metadata": {
        "id": "e5Qsjr1-5IbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np\n",
        "\n",
        "# Danh sách các label theo thứ tự class index\n",
        "labels = ['airplane', 'apple', 'bag', 'ball', 'bamboo', 'banana', 'basketball', 'beach', 'bicycle', 'bird', 'book', 'bottle', 'bread', 'cactus', 'cake', 'candle', 'car', 'cat', 'chair', 'city', 'clock', 'cow', 'cup', 'desert', 'dog', 'duck', 'elephant', 'fish', 'flag', 'flower', 'forest', 'goat', 'grass', 'guitar', 'hat', 'horse', 'house', 'key', 'laptop', 'lion', 'mango', 'mountain', 'ocean', 'orchid', 'palm tree', 'panda', 'pen', 'pencil', 'penguin', 'phone', 'pine tree', 'pizza', 'rabbit', 'river', 'rose', 'sheep', 'ship', 'shoes', 'sky', 'sun', 'sunflower', 'table', 'tiger', 'train', 'tree', 'volcano', 'water', 'waterfall']\n",
        "\n",
        "\n",
        "# Đường dẫn tới ảnh cần kiểm tra\n",
        "# image_path = '/content/drive/MyDrive/dataset_image/beach/Image_1.jpg'\n",
        "# image_path = '/content/drive/MyDrive/dataset_image/ball/Image_1.jpg'\n",
        "# image_path = '/content/drive/MyDrive/dataset_image/sky/Image_1.jpg'\n",
        "# image_path = '/content/drive/MyDrive/dataset_image/pencil/Image_1.jpg'\n",
        "image_path = '/content/drive/MyDrive/dataset_image/airplane/Image_11.jpg'\n",
        "\n",
        "# Tiền xử lý ảnh\n",
        "image = load_img(image_path, target_size=(224, 224))  # Resize ảnh\n",
        "image = img_to_array(image)  # Chuyển đổi ảnh thành mảng\n",
        "image = np.expand_dims(image, axis=0)  # Thêm chiều batch\n",
        "image = image / 255.0  # Chuẩn hóa dữ liệu ảnh\n",
        "\n",
        "# Dự đoán lớp của ảnh\n",
        "predictions = model.predict(image)\n",
        "\n",
        "# Lấy chỉ số lớp có xác suất cao nhất\n",
        "predicted_class_index = np.argmax(predictions)\n",
        "\n",
        "# Lấy nhãn lớp từ danh sách nhãn\n",
        "predicted_class_name = labels[predicted_class_index]\n",
        "\n",
        "# In ra nhãn lớp dự đoán\n",
        "print(f\"Predicted Class: {predicted_class_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Clhtewg5LSV",
        "outputId": "d26ea81b-e2ac-4118-da76-996224efa325"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "Predicted Class: airplane\n"
          ]
        }
      ]
    }
  ]
}